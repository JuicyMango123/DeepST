{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# understand system and version\n",
    "import sys\n",
    "print(sys.version)\n",
    "!jupyter kernelspec list\n",
    "import pdb\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "_cell_guid": "b1076dfc-b9ad-4769-8c92-a6c4dae69d19",
    "_uuid": "8f2839f25d086af736a60e9eeb907d3b93b6e0e5",
    "tags": []
   },
   "outputs": [],
   "source": [
    "# This Python 3 environment comes with many helpful analytics libraries installed\n",
    "# Here's several helpful packages to load\n",
    "\n",
    "import numpy as np # linear algebra\n",
    "import pandas as pd # data processing, CSV file I/O (e.g. pd.read_csv)\n",
    "\n",
    "# Input data files are available in the read-only \"../input/\" directory\n",
    "# For example, running this (by clicking run or pressing Shift+Enter) will list all files under the input directory\n",
    "\n",
    "import os  # use OS dependent functions like reading or writing files\n",
    "os.environ['NUMEXPR_MAX_THREADS'] = '10' # default is 8, Mac Book M1 Pro has 10 can support 10, which may slow down the computer\n",
    "import re  # regular expressions in Python for searching patterns\n",
    "\n",
    "import torch\n",
    "import random\n",
    "device = 'cuda' if torch.cuda.is_available() else 'cpu'\n",
    "import torch.nn as nn  # base class for all neural network modules in PyTorch\n",
    "from glob import glob  # find all the pathnames matching a specified pattern according to the rules used by the Unix shell\n",
    "from matplotlib import pyplot as plt # plot libary\n",
    "import collections # build-in types\n",
    "from tqdm import tqdm # provides a progress bar for loops and iterators\n",
    "from itertools import chain # provides iterations \n",
    "from nltk.translate.bleu_score import sentence_bleu, SmoothingFunction # Natural Language Toolkit (nltk)\n",
    "\n",
    "import matplotlib.pyplot as plt # for analyze dataset"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "tags": []
   },
   "source": [
    "# Config"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "class Config:\n",
    "    train_test_ratio = 0.9 # the proportion of data that will be used for training versus testing\n",
    "    E = 128\n",
    "    V = 128\n",
    "    L = None\n",
    "    N = None\n",
    "    # use the content of the decoder's first dimension (=V) as three transformer decoder's first part of input\n",
    "    # channel: AWGN\n",
    "    sigma = 0.1  #standard deviation of the Additive White Gaussian Noise (AWGN)\n",
    "    loss_lambda = 1 # a weighting factor for the loss function\n",
    "    clipping_max = 1.  # a threshold for clipping the gradients during training\n",
    "    num_steps = 40 # number of steps for the training process\n",
    "CONFIG = Config()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "tags": []
   },
   "source": [
    "# Preprocess"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████████████████████████████████| 9672/9672 [01:01<00:00, 157.62it/s]\n",
      "100%|████████████████████████████████| 442552/442552 [00:09<00:00, 46914.16it/s]\n",
      "100%|██████████████████████████████████| 49173/49173 [00:01<00:00, 46563.68it/s]\n"
     ]
    }
   ],
   "source": [
    "# Here, use Europarl.tgz that is a dataset that contains transcripts of the proceedings of \n",
    "# the European Parliament. The dataset includes texts in multiple languages, including English, \n",
    "# French, German, Italian, and Spanish. This program only use English.\n",
    "#\n",
    "# # !tar -zxvf ./europarl.tgz >/dev/null 2>&1\n",
    "# # print('Conpression Finished')\n",
    "txt_list = glob('txt/en/*')\n",
    "file_cnt = 0\n",
    "text = []  # corpus‘ split sentences\n",
    "sentence_lengths = []\n",
    "\n",
    "\n",
    "# # find characters ',.!?', if its previous character is a space, return true\n",
    "def no_space(char, prev_char):\n",
    "    return char in set(',.!?') and prev_char != ' '\n",
    "\n",
    "# Process a set of text files, split them into sentences, and store them in a list. \n",
    "# It also checks for empty sentences, and splits sentences that are too long (greater 40 words).\n",
    "for txt_file in tqdm(txt_list):\n",
    "    if file_cnt % 1000 == 999:\n",
    "        print(f'processed{file_cnt}text')\n",
    "    unprocessed_text = open(txt_file, 'r').read().replace('\\xa0', ' ')\n",
    "    splitted_text = re.split(r'\\n|<.*>|\\.|!|\\?', unprocessed_text)\n",
    "    i = 0\n",
    "    while i <= len(splitted_text) - 1:\n",
    "        if splitted_text[i] == '' or splitted_text[i] == ' ':\n",
    "            del splitted_text[i]\n",
    "            continue\n",
    "                \n",
    "        if len(splitted_text[i]) > 50:\n",
    "            space_cnt = 0\n",
    "            j = 0\n",
    "            while j <= len(splitted_text[i]) - 1:\n",
    "                if splitted_text[i][j] == ' ':\n",
    "                    space_cnt += 1\n",
    "                j += 1\n",
    "                if space_cnt == 50:\n",
    "                    splitted_text.append(splitted_text[i][:j - 1])\n",
    "                    splitted_text[i] = splitted_text[i][j:]\n",
    "                    j = 0\n",
    "                    space_cnt = 0\n",
    "        i += 1\n",
    "    text += splitted_text\n",
    "\n",
    "\n",
    "''' the following codes are used to analysis the distribution of sentence length in the dataset\n",
    "# Iterate through the dataset\n",
    "for sentence in text:\n",
    "    # Append the length of the sentence to the list\n",
    "    sentence_lengths.append(len(sentence.split()))\n",
    "\n",
    "# Plot a histogram of the sentence lengths\n",
    "plt.hist(sentence_lengths, bins=50)\n",
    "plt.xlabel(\"Sentence Length\")\n",
    "plt.ylabel(\"Frequency\")\n",
    "plt.show()\n",
    "\n",
    "# The percentage of sentences that are longer than a certain length\n",
    "max_length = 30\n",
    "sentence_count = len(sentence_lengths)\n",
    "long_sentences = [s for s in sentence_lengths if s>max_length]\n",
    "percentage = len(long_sentences)/sentence_count*100\n",
    "print(f\"{percentage:.2f}% of sentences are longer than {max_length} words.\")\n",
    "\n",
    "only need to run onetime to determine the best split set in above code'''\n",
    "\n",
    "# # # first 1/10th of the original text\n",
    "text = text[:int(len(text) / 5)]\n",
    "    \n",
    "# # create corpus in txt\n",
    "train_txt = open('./corpus_train.txt', 'w')\n",
    "val_txt = open('./corpus_val.txt', 'w')\n",
    "\n",
    "train_len = int(len(text) * CONFIG.train_test_ratio) # 90% of corpus is used for training\n",
    "# process a list of sentences and write them to a file, while also preserving the integrity \n",
    "# of the punctuation marks in the sentences by adding a space before certain punctuation marks\n",
    "for sentence in tqdm(text[:train_len]):\n",
    "    out = [' ' + char if j > 0 and no_space(char, sentence[j - 1]) else char\n",
    "        for j, char in enumerate(sentence)]\n",
    "    train_txt.write((''.join(out)).strip() + '\\n')\n",
    "\n",
    "# like the previous for loop, here process the remaining 10% of text in a different file (testing)\n",
    "for sentence in tqdm(text[train_len:]):\n",
    "    out = [' ' + char if j > 0 and no_space(char, sentence[j - 1]) else char\n",
    "        for j, char in enumerate(sentence)]\n",
    "    val_txt.write((''.join(out)).strip() + '\\n')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: subword-nmt in /Users/dijiang/anaconda3/lib/python3.9/site-packages (0.3.8)\n",
      "Requirement already satisfied: tqdm in /Users/dijiang/anaconda3/lib/python3.9/site-packages (from subword-nmt) (4.64.1)\n",
      "Requirement already satisfied: mock in /Users/dijiang/anaconda3/lib/python3.9/site-packages (from subword-nmt) (4.0.3)\n",
      "100%|###################################| 30000/30000 [00:19<00:00, 1576.83it/s]\n"
     ]
    }
   ],
   "source": [
    "## commandline\n",
    "!pip install subword-nmt\n",
    "!subword-nmt learn-bpe -s 30000 < ./corpus_train.txt > ./corpus_train.bpe\n",
    "!subword-nmt apply-bpe -c ./corpus_train.bpe < ./corpus_train.txt > ./corpus_train_split.txt\n",
    "!subword-nmt apply-bpe -c ./corpus_train.bpe < ./corpus_val.txt > ./corpus_val_split.txt\n",
    "!subword-nmt get-vocab --input ./corpus_train_split.txt --output ./corpus_train_vocab.txt"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# vocab"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "class Vocab:  \n",
    "#   text vocabulary\n",
    "    # __init__ sorts the tokens by frequency in descending order, and assigns an index to each token\n",
    "    def __init__(self, tokens=None, min_freq=0, reserved_tokens=None): \n",
    "        if tokens is None:\n",
    "            tokens = []\n",
    "        if reserved_tokens is None:\n",
    "            reserved_tokens = []\n",
    "        counter = tokens\n",
    "        self._token_freqs = sorted(counter.items(), key=lambda x: x[1],  \n",
    "                                   reverse=True)            # A list of tokens sorted by frequency\n",
    "        # Unknown tokens have an index of 0\n",
    "        self.idx_to_token = ['<unk>'] + reserved_tokens  # List, idx corresponds to the position of token\n",
    "        self.token_to_idx = {token: idx\n",
    "                             for idx, token in enumerate(self.idx_to_token)}\n",
    "        for token, freq in self._token_freqs:\n",
    "            if freq < min_freq:\n",
    "                break\n",
    "            if token not in self.token_to_idx:\n",
    "                self.idx_to_token.append(token)\n",
    "                self.token_to_idx[token] = len(self.idx_to_token) - 1\n",
    "\n",
    "    def __len__(self): # returns the length of the vocabulary\n",
    "        return len(self.idx_to_token)\n",
    "\n",
    "    def __getitem__(self, tokens): # returns the index of a given token\n",
    "        if not isinstance(tokens, (list, tuple)):\n",
    "            return self.token_to_idx.get(tokens, self.unk)\n",
    "        return [self.__getitem__(token) for token in tokens]\n",
    "\n",
    "    def to_tokens(self, indices): # returns the token corresponding to a given index\n",
    "        if not isinstance(indices, (list, tuple)):\n",
    "            return self.idx_to_token[indices]\n",
    "        return [self.idx_to_token[index] for index in indices]\n",
    "\n",
    "    @property\n",
    "    def unk(self):  # Unknown tokens have an index of 0\n",
    "        return 0\n",
    "\n",
    "    @property\n",
    "    def token_freqs(self): # returns the list of token frequencies that was sorted in descending order during initialization of the Vocab class.\n",
    "        return self._token_freqs\n",
    "\n",
    "def count_corpus(tokens):  \n",
    "    \"\"\"Count the frequency of words\"\"\"\n",
    "    # The tokens here are 1D list or 2D list\n",
    "    if len(tokens) == 0 or isinstance(tokens[0], list):\n",
    "        # Flattens a list of tokens into a list\n",
    "        tokens = [token for line in tokens for token in line]\n",
    "    return collections.Counter(tokens)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "vocab_list = open('./corpus_train_vocab.txt').readlines() \n",
    "vocab_dict = {}  # create an empty dictionary\n",
    "for key_value_pair in vocab_list:\n",
    "    key_value_pair = key_value_pair.strip().split()\n",
    "    vocab_dict[key_value_pair[0]] = int(key_value_pair[1]) # in the vocabulary list, key is token and value is the frequency\n",
    "source_vocab = Vocab(collections.Counter(vocab_dict), reserved_tokens=['<pad>', '<eos>', '<bos>'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "train_corpus = open('./corpus_train_split.txt', 'r').readlines()  # the special \"\\n\" has not been processed\n",
    "\n",
    "class EuroParlDataset(torch.utils.data.Dataset):  # define Pytorch data set\n",
    "    def __init__(self, vocab=source_vocab, corpus=train_corpus):\n",
    "        self.vocab = vocab\n",
    "        self.corpus = corpus\n",
    "        \n",
    "    def __len__(self):\n",
    "        return len(self.corpus)\n",
    "    \n",
    "    def __getitem__(self, index):\n",
    "        sentence = self.corpus[index].strip().split() + ['<eos>']\n",
    "        return self.vocab[sentence], len(sentence)\n",
    "    \n",
    "# collate_fn combines a list of samples into a single batch：\n",
    "# sorts the batch data by the length of the sentence, in descending order;\n",
    "# extracts the length of the sentences, and converts the sentences into tensors;\n",
    "# pads the tensors to the maximum length of the sentences in the batch.\n",
    "def collate_fn(batch_data): \n",
    "    batch_data.sort(key=lambda xi: len(xi[0]), reverse=True)\n",
    "    data_length = [xi[1] for xi in batch_data]\n",
    "    data = [torch.tensor(xi[0]) for xi in batch_data]\n",
    "    padded_data = nn.utils.rnn.pad_sequence(data, batch_first=True, padding_value=1)\n",
    "    return padded_data, torch.tensor(data_length)\n",
    "\n",
    "# loads the text data from corpus_train_split.txt and converts it into numerical representations using the vocabulary, with the <eos> token appended to each sentence. \n",
    "# Then the dataset is loaded in batches of 32, shuffled, and padded to the maximum length of the sentence in each batch.\n",
    "data_loader = torch.utils.data.DataLoader(dataset=EuroParlDataset(), batch_size=32, shuffle=True, collate_fn=collate_fn)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# pipeline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# The system  uses nn.embedding\n",
    "# L E V N setup: E=128， V=128"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# backbone"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "torch.set_printoptions(threshold=np.inf)\n",
    "# MI needs to be masked; mask first and then sample\n",
    "# decoder needs to be masked\n",
    "# phase=2 needs chain\n",
    "class PositionalEncoding(nn.Module):\n",
    "    \"\"\"position encoding\"\"\"\n",
    "    def __init__(self, num_hiddens, dropout, max_len=1000):\n",
    "        super(PositionalEncoding, self).__init__()\n",
    "        self.dropout = nn.Dropout(dropout)\n",
    "        # Create a long enough P\n",
    "        self.P = torch.zeros((1, max_len, num_hiddens))\n",
    "        X = torch.arange(max_len, dtype=torch.float32).reshape(\n",
    "            -1, 1) / torch.pow(10000, torch.arange(\n",
    "            0, num_hiddens, 2, dtype=torch.float32) / num_hiddens)\n",
    "        self.P[:, :, 0::2] = torch.sin(X)\n",
    "        self.P[:, :, 1::2] = torch.cos(X)\n",
    "\n",
    "    def forward(self, X):\n",
    "        X = X + self.P[:, :X.shape[1], :].to(X.device)\n",
    "        return self.dropout(X)\n",
    "\n",
    "class MyEmbedding(nn.Module):\n",
    "    def __init__(self, vocab=source_vocab):\n",
    "        super(MyEmbedding, self).__init__()\n",
    "        self.embedding = nn.Embedding(len(vocab), CONFIG.E, padding_idx=vocab['<pad>'])\n",
    "        \n",
    "    def forward(self, X):\n",
    "        return self.embedding(X)\n",
    "    \n",
    "class Encoder(nn.Module):\n",
    "    def __init__(self, vocab=source_vocab):\n",
    "        super(Encoder, self).__init__()\n",
    "        self.position_encoding = PositionalEncoding(CONFIG.V, dropout=0.1)\n",
    "        self.transformer_encoder1 = nn.TransformerEncoderLayer(d_model=CONFIG.V, nhead=8, dim_feedforward=512,  # other's parameter\n",
    "                                                              batch_first=True)\n",
    "        self.transformer_encoder2 = nn.TransformerEncoderLayer(d_model=CONFIG.V, nhead=8, dim_feedforward=512,  # other's parameter\n",
    "                                                              batch_first=True)\n",
    "        self.transformer_encoder3 = nn.TransformerEncoderLayer(d_model=CONFIG.V, nhead=8, dim_feedforward=512,  # other's parameter\n",
    "                                                              batch_first=True)\n",
    "        self.linear1 = nn.Linear(CONFIG.V, 2 * CONFIG.V)\n",
    "        self.relu1 = nn.ReLU()\n",
    "        self.linear2 = nn.Linear(2 * CONFIG.V, 16)\n",
    "        self.relu2 = nn.ReLU()\n",
    "        \n",
    "    def forward(self, X, valid_lens):\n",
    "        mask = (torch.arange((X.shape[1]), device=device).unsqueeze(0) >= valid_lens.unsqueeze(1)).to(device)\n",
    "        X2 = self.position_encoding(X)\n",
    "        X3 = self.transformer_encoder1(X2, src_key_padding_mask=mask)\n",
    "        X4 = self.transformer_encoder2(X3, src_key_padding_mask=mask)\n",
    "        X5 = self.transformer_encoder3(X4, src_key_padding_mask=mask)\n",
    "        X6 = self.linear1(X5)\n",
    "        X7 = self.relu1(X6)\n",
    "        X8 = self.linear2(X7)\n",
    "        X9 = self.relu2(X8)\n",
    "        return X9\n",
    "        \n",
    "def Channel(X):  # AWGN\n",
    "    return X + torch.normal(0, CONFIG.sigma, size=X.shape).to(device)\n",
    "        \n",
    "class Decoder(nn.Module):\n",
    "    def __init__(self, vocab=source_vocab):\n",
    "        super(Decoder, self).__init__()\n",
    "        # reshape\n",
    "        self.position_encoding = PositionalEncoding(CONFIG.V, dropout=0.1)\n",
    "        self.linear1 = nn.Linear(16, 2 * CONFIG.V)\n",
    "        self.relu1 = nn.ReLU()\n",
    "        self.linear2 = nn.Linear(2 * CONFIG.V, CONFIG.V)\n",
    "        self.relu2 = nn.ReLU()\n",
    "        self.transformer_decoder1 = nn.TransformerDecoderLayer(d_model=CONFIG.V, nhead=8, dim_feedforward=512,  # 别人的参数\n",
    "                                                              batch_first=True)\n",
    "        self.transformer_decoder2 = nn.TransformerDecoderLayer(d_model=CONFIG.V, nhead=8, dim_feedforward=512,  # 别人的参数\n",
    "                                                              batch_first=True)\n",
    "        self.transformer_decoder3 = nn.TransformerDecoderLayer(d_model=CONFIG.V, nhead=8, dim_feedforward=512,  # 别人的参数\n",
    "                                                              batch_first=True)\n",
    "        self.linear3 = nn.Linear(CONFIG.V, len(source_vocab))\n",
    "#         self.softmax = nn.Softmax(dim=2)  # ?\n",
    "        \n",
    "    def forward(self, emb_decoder_input, channel_output, origin_len, tgt_mask=None, mode='train'):\n",
    "        memory_mask = (torch.arange((channel_output.shape[1]), dtype=torch.float32,\n",
    "                            device=device)[None, :] >= origin_len[:, None]).to(device)\n",
    "        channel_output = self.linear1(channel_output)\n",
    "        channel_output = self.relu1(channel_output)\n",
    "        channel_output = self.linear2(channel_output)\n",
    "        memory = self.relu2(channel_output)\n",
    "        emb_decoder_input = self.position_encoding(emb_decoder_input)\n",
    "        X6 = self.transformer_decoder1(emb_decoder_input, memory, tgt_mask=tgt_mask, memory_key_padding_mask=memory_mask, tgt_key_padding_mask=memory_mask if mode == 'train' else None)\n",
    "        X7 = self.transformer_decoder2(X6, memory, tgt_mask=tgt_mask, memory_key_padding_mask=memory_mask, tgt_key_padding_mask=memory_mask if mode == 'train' else None)\n",
    "        X8 = self.transformer_decoder3(X7, memory, tgt_mask=tgt_mask, memory_key_padding_mask=memory_mask, tgt_key_padding_mask=memory_mask if mode == 'train' else None)\n",
    "        X9 = self.linear3(X8)\n",
    "#        X9 = self.softmax(X9, dim=-1)\n",
    "        return X9\n",
    "#         return self.softmax(X9)\n",
    "    \n",
    "class DeepST(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(DeepST, self).__init__()\n",
    "        self.encoder = Encoder()\n",
    "        self.channel = Channel\n",
    "        self.decoder = Decoder()\n",
    "        \n",
    "    def forward(self, emb_encoder_input, valid_lens, emb_decoder_input=None, embedding=None, phase=1):  # valid_lens是含<eos>\n",
    "        '''\n",
    "        x: (batch_size, N, E)\n",
    "        '''\n",
    "        encode_result = self.encoder(emb_encoder_input, valid_lens)\n",
    "        channel_outputs = self.channel(encode_result)\n",
    "        if phase == 2:\n",
    "            mask = (torch.triu(torch.ones(emb_decoder_input.shape[1], emb_decoder_input.shape[1])) == 1).transpose(0, 1)\n",
    "            mask = (mask.masked_fill(mask == 0, True).masked_fill(mask == 1, False)).to(device)\n",
    "            return encode_result, self.channel(encode_result), \\\n",
    "                   self.decoder(torch.cat([embedding(torch.full([emb_decoder_input.shape[0], 1], source_vocab['<bos>'], dtype=torch.long, device=device)), \n",
    "                                        emb_decoder_input[:, :-1, :]], dim=1).to(device), \n",
    "                                channel_outputs,\n",
    "                                valid_lens, \n",
    "                                mask)\n",
    "        else:\n",
    "            return encode_result, self.channel(encode_result)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "class MI(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(MI, self).__init__()\n",
    "        self.linear1 = nn.Linear(16 * 2, 2 * CONFIG.V)\n",
    "        self.relu1 = nn.ReLU()\n",
    "        self.linear2 = nn.Linear(2 * CONFIG.V, 2 * CONFIG.V)\n",
    "        self.relu2 = nn.ReLU()\n",
    "        self.linear3 = nn.Linear(2 * CONFIG.V, 1)\n",
    "        self.relu3 = nn.ReLU()\n",
    "        \n",
    "    def network(self, X, Y):\n",
    "        return self.relu3(self.linear3(self.relu2(self.linear2(self.relu1(self.linear1(torch.cat([X, Y], dim=1)))))))\n",
    "        \n",
    "    def forward(self, X, Y, valid_lens): \n",
    "        \n",
    "        mask = (torch.arange((X.shape[1]), dtype=torch.long,\n",
    "                            device=X.device)[None, :] >= valid_lens[:, None]).reshape(-1)\n",
    "        # Reshape X and Y first, then take them out\n",
    "        X = X.reshape(-1, 16)\n",
    "        Y = Y.reshape(-1, 16)\n",
    "        \n",
    "        X = X[mask == False]\n",
    "        Y = Y[mask == False]\n",
    "        \n",
    "        # sample\n",
    "        sample_size = X.shape[0]\n",
    "        idx = list(range(sample_size))\n",
    "        random.shuffle(idx)\n",
    "        idx = torch.tensor(idx).to(device)\n",
    "        X = X[idx]\n",
    "        Y = Y[idx]\n",
    "        idx_shuffle = list(range(sample_size))\n",
    "        random.shuffle(idx_shuffle)\n",
    "        idx_shuffle = torch.tensor(idx_shuffle).to(device)\n",
    "        shuffle_Y = Y[idx_shuffle]\n",
    "        \n",
    "        output_joint = self.network(X, Y)\n",
    "        output_marginal = self.network(X, shuffle_Y)\n",
    "        \n",
    "        return output_joint, output_marginal"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# loss"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "\n",
    "def mi_criterion(x, y):\n",
    "    max_y = torch.max(y)\n",
    "    return torch.mean(x) - (max_y + torch.log(torch.mean(torch.exp(y - max_y))))\n",
    "\n",
    "class MaskedSoftmaxCELoss(nn.CrossEntropyLoss):\n",
    "    def sequence_mask(self, X, valid_len, value=0):\n",
    "        \"\"\"\n",
    "        Mask out irrelevant items in a sequence\n",
    "        X: (batch_size, maxlen)\n",
    "        \"\"\"\n",
    "        maxlen = X.size(1)\n",
    "        mask = torch.arange((maxlen), dtype=torch.float32,\n",
    "                            device=X.device)[None, :] < valid_len[:, None]\n",
    "        X[~mask] = value\n",
    "        return X\n",
    "    \n",
    "    \"\"\"Softmax cross-entropy loss function with masking\"\"\"\n",
    "    # pred's shape：(batch_size,num_steps,vocab_size)\n",
    "    # label's shape：(batch_size,num_steps)\n",
    "    # valid_len's shape：(batch_size,)\n",
    "    def forward(self, pred, label, valid_len):\n",
    "        weights = torch.ones_like(label)\n",
    "        weights = self.sequence_mask(weights, valid_len)\n",
    "        self.reduction='mean'\n",
    "        unweighted_loss = super(MaskedSoftmaxCELoss, self).forward(\n",
    "            pred.permute(0, 2, 1), label)\n",
    "        weighted_loss = (unweighted_loss * weights).mean(dim=1)\n",
    "        return weighted_loss"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "MI(\n",
       "  (linear1): Linear(in_features=32, out_features=256, bias=True)\n",
       "  (relu1): ReLU()\n",
       "  (linear2): Linear(in_features=256, out_features=256, bias=True)\n",
       "  (relu2): ReLU()\n",
       "  (linear3): Linear(in_features=256, out_features=1, bias=True)\n",
       "  (relu3): ReLU()\n",
       ")"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "embedding = MyEmbedding()\n",
    "embedding.to(device)\n",
    "model = DeepST()\n",
    "model.to(device)\n",
    "mi_model = MI()\n",
    "mi_model.to(device)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "batch_total_loss_list, batch_mi_loss_list = [], []\n",
    "epoch_total_loss_list, epoch_mi_loss_list = [], []"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "'''This is a training script for a model that includes two phases. In the first phase, \n",
    "the model optimizes the mutual information (MI) loss using the Adam optimizer.\n",
    "The script initializes the mutual information (MI) model and optimizer, and applies \n",
    "the Kaiming uniform initialization to the model's weights. It then trains the model for 20 epochs, \n",
    "where in each epoch it iterates through the data loader and calculates the MI loss using the MI criterion. \n",
    "The gradients are then calculated, clipped to a certain value using torch.nn.utils.clip_grad_norm_ \n",
    "and the optimizer steps to update the model's parameters. It also keeps track of the running MI loss, \n",
    "and the batch and epoch MI loss, which are plotted at various points during training to visualize the loss.\n",
    "\n",
    "In the second phase of training, the script initializes the optimizer for both the model and the embedding layer. \n",
    "It also sets the model to train mode. It then trains the model for 15 epochs, where in each epoch it iterates \n",
    "through the data loader and calculates the transceiver loss using the criterion and passing the input through \n",
    "the model and the embedding layer. The gradients are then calculated, clipped to a certain value using \n",
    "torch.nn.utils.clip_grad_norm_ and the optimizer steps to update the model's parameters and the embedding \n",
    "layer's parameters. It also keeps track of the running total loss, and the batch and epoch total loss, \n",
    "which are plotted at various points during training to visualize the loss.\n",
    "\n",
    "It is also worth noting that the script is using the MaskedSoftmaxCELoss as the criterion, this loss is a \n",
    "variation of the softmax cross-entropy loss, but it takes into account the padding of the input sequence \n",
    "and masks the loss for the padded values so that they do not contribute to the loss calculation.\n",
    "'''\n",
    "# valid_lens has eos but not bos\n",
    "def train(model=model, clipping_max=CONFIG.clipping_max, num_steps=CONFIG.num_steps, phase=1):\n",
    "    \n",
    "    #def init_weights(m):\n",
    "    #    if type(m) == nn.Linear:\n",
    "    #        nn.init.kaiming_uniform_(m.weight)\n",
    "    \n",
    "    criterion = MaskedSoftmaxCELoss()\n",
    "    \n",
    "    \n",
    "    if phase == 1:\n",
    "        mi_optimizer = torch.optim.Adam(mi_model.parameters(), lr=5e-5)\n",
    "        mi_model.apply(init_weights)\n",
    "        for epoch in range(20):\n",
    "            running_mi_loss = 0.\n",
    "            batch_cnt = 0\n",
    "            batch_num = len(data_loader)\n",
    "            for index, data in enumerate(tqdm(data_loader), 0):\n",
    "                # phase == 1\n",
    "                mi_optimizer.zero_grad()\n",
    "                inputs, valid_lens = data\n",
    "                inputs, valid_lens = inputs.to(device), valid_lens.to(device)\n",
    "                emb_inputs = embedding(inputs)\n",
    "                encode_outputs, channel_outputs = model(emb_inputs, valid_lens, phase=1)\n",
    "                x, y = mi_model(encode_outputs, channel_outputs, valid_lens)\n",
    "                mi_loss = -mi_criterion(x, y)\n",
    "                mi_loss.backward()\n",
    "                torch.nn.utils.clip_grad_norm_(mi_model.parameters(), clipping_max)\n",
    "                mi_optimizer.step()\n",
    "                running_mi_loss += float(mi_loss.data)\n",
    "                batch_mi_loss_list.append(float(mi_loss.data))\n",
    "                if batch_cnt > batch_num / 5:\n",
    "                    print(f'now batch:{index} in epoch {epoch}')\n",
    "                    batch_cnt = 0\n",
    "                    plt.plot(batch_mi_loss_list)\n",
    "                    plt.title('batch_mi_loss_list')\n",
    "                    plt.show()\n",
    "                batch_cnt += 1\n",
    "                \n",
    "            \n",
    "            with torch.no_grad():\n",
    "                print('===' * 10, 'epoch:', epoch, 'loss:', running_mi_loss)\n",
    "                epoch_mi_loss_list.append(running_mi_loss)\n",
    "                plt.plot(epoch_mi_loss_list)\n",
    "                plt.title('epoch_mi_loss_list')\n",
    "                plt.show()\n",
    "            \n",
    "    else:\n",
    "        optimizer = torch.optim.Adam(chain(embedding.parameters(), model.parameters()), lr=1e-3)\n",
    "#         model.apply(init_weights)\n",
    "        val_bleus = []\n",
    "        for epoch in range(15):\n",
    "            running_total_loss, running_mi_loss = 0., 0.  # initialize loss\n",
    "            model.train()\n",
    "            batch_cnt = 0\n",
    "            batch_num = len(data_loader)\n",
    "            \n",
    "            for index, data in enumerate(tqdm(data_loader), 0):\n",
    "                # phase == 2\n",
    "                optimizer.zero_grad()\n",
    "                inputs, valid_lens = data\n",
    "                inputs, valid_lens = inputs.to(device), valid_lens.to(device)\n",
    "                emb_inputs = embedding(inputs)\n",
    "                encode_outputs, channel_outputs, outputs = model(emb_inputs, valid_lens, emb_inputs, embedding, phase=2)\n",
    "\n",
    "#                x, y = mi_model(encode_outputs, channel_outputs, valid_lens)\n",
    "#                mi_loss = -mi_criterion(x, y)\n",
    "#                if batch_cnt % 5000 == 4999:\n",
    "#                    print(f'sample:{source_vocab.to_tokens(inputs[0, :valid_lens[0], :])}->{source_vocab.to_tokens(outputs[0, :valid_lens[0], :].argmax(dim=1))}')\n",
    "                transceiver_loss = criterion(outputs, inputs, valid_lens).mean()\n",
    "#                total_loss = transceiver_loss + CONFIG.loss_lambda * mi_loss\n",
    "                total_loss = transceiver_loss\n",
    "                total_loss.backward()\n",
    "                torch.nn.utils.clip_grad_norm_(chain(embedding.parameters(), model.parameters()), clipping_max)\n",
    "                optimizer.step()\n",
    "                running_total_loss += float(total_loss.data)\n",
    "#                running_mi_loss += float(mi_loss.data)\n",
    "                batch_total_loss_list.append(float(total_loss.data))\n",
    "#                batch_mi_loss_list.append(float(mi_loss.data))            \n",
    "\n",
    "                batch_cnt += 1\n",
    "                if batch_cnt > batch_num / 5:\n",
    "                    print(f'now batch:{index} in epoch {epoch}')\n",
    "                    batch_cnt = 0\n",
    "#                    plt.plot(batch_mi_loss_list)\n",
    "#                    plt.title('batch_mi_loss_list')\n",
    "#                    plt.show()\n",
    "                    plt.plot(batch_total_loss_list)\n",
    "                    plt.title('batch_total_loss_list')\n",
    "                    plt.show()\n",
    "\n",
    "            print('===' * 10, 'epoch:', epoch, 'loss:', running_total_loss)\n",
    "            try:\n",
    "                print('train sample:')\n",
    "                for i in range(5):\n",
    "                    print(source_vocab.to_tokens(list(inputs[i].cpu().numpy())), '\\n->\\n', source_vocab.to_tokens(list(outputs[i, 1:].detach().cpu().argmax(dim=1).numpy())))\n",
    "                \n",
    "            except:\n",
    "                pass\n",
    "            \n",
    "            epoch_total_loss_list.append(running_total_loss)\n",
    "#            epoch_mi_loss_list.append(running_mi_loss)\n",
    "            plt.plot(epoch_total_loss_list)\n",
    "            plt.title('epoch_total_loss_list')\n",
    "            plt.show()\n",
    "#            plt.plot(epoch_mi_loss_list)\n",
    "#            plt.title('epoch_mi_loss_list')\n",
    "#            plt.show()\n",
    "            \n",
    "            if epoch <= 1 or epoch_total_loss_list[-1] < epoch_total_loss_list[-2]:\n",
    "                torch.save(model.state_dict(), 'model.pth')\n",
    "                torch.save(embedding.state_dict(), 'embedding.pth')\n",
    "    \n",
    "            with torch.no_grad():\n",
    "                model.eval()\n",
    "                bleus = []\n",
    "                val_corpus = open('./corpus_val_split.txt', 'r').readlines()\n",
    "                val_data_loader = torch.utils.data.DataLoader(dataset=EuroParlDataset(corpus=val_corpus), batch_size=32, shuffle=True, collate_fn=collate_fn)\n",
    "                for index, data in enumerate(tqdm(val_data_loader), 0):\n",
    "                    inputs, valid_lens = data\n",
    "                    inputs, valid_lens = inputs.to(device), valid_lens.to(device)\n",
    "                    emb_inputs = embedding(inputs)\n",
    "                    _, channel_outputs = model(emb_inputs, valid_lens, phase=1)\n",
    "                    # decoder's first one is <bos>\n",
    "                    outputs = torch.cat([torch.full([inputs.shape[0], 1], source_vocab['<bos>'], dtype=torch.long, device=device), \n",
    "                                         torch.full([inputs.shape[0], num_steps - 1], source_vocab['<pad>'], dtype=torch.long, device=device)], \n",
    "                                        dim=1).to(device)\n",
    "                    # continue_idx marks which sentences can continue to be generated\n",
    "                    continue_idx = torch.arange(inputs.shape[0], device=device)\n",
    "                    num_step = 0\n",
    "                    while not len(continue_idx) == 0 and num_step < num_steps - 1:\n",
    "                        emb_outputs = embedding(outputs[continue_idx, :num_step + 1])\n",
    "                        pred_words = model.decoder(emb_outputs, channel_outputs[continue_idx], valid_lens[continue_idx], mode='validate').argmax(dim=2)[:, -1:]\n",
    "                        outputs[continue_idx, num_step + 1] = pred_words.squeeze(1)\n",
    "                        continue_idx = continue_idx[(pred_words != source_vocab['<eos>']).squeeze(1)]\n",
    "                        num_step += 1\n",
    "                    for i in range(inputs.shape[0]):\n",
    "                        bleus.append(sentence_bleu([list(inputs[i].cpu().numpy())], list(outputs[i, 1:].cpu().numpy()), smoothing_function=SmoothingFunction().method1))\n",
    "\n",
    "                try:\n",
    "                    print('val sample:')\n",
    "                    for i in range(5):\n",
    "                        print(source_vocab.to_tokens(list(inputs[i].cpu().numpy())), '\\n->\\n', source_vocab.to_tokens(list(outputs[i, 1:].cpu().numpy())))\n",
    "                except:\n",
    "                    pass\n",
    "# check if input and output has the same shape\n",
    "#                if inputs.shape == outputs.shape:\n",
    "#                    for i in range(len(inputs)):\n",
    "#                        print(source_vocab.to_tokens(list(inputs[i].cpu().numpy())), '\\n->\\n', source_vocab.to_tokens(list(outputs[i, 1:].cpu().numpy())))\n",
    "#                        # print everything\n",
    "#                        # print(source_vocab.to_tokens(list(inputs[i].cpu().numpy())), '\\n->\\n', source_vocab.to_tokens(list(outputs[i].cpu().numpy())))\n",
    "#                else:\n",
    "#                    print(\"The shape of inputs tensor: \", inputs.shape)\n",
    "#                    print(\"The shape of outputs tensor: \", outputs.shape)\n",
    "                print(f'val bleu mean:{sum(bleus) / len(bleus)}')\n",
    "                val_bleus.append(sum(bleus) / len(bleus))\n",
    "                plt.plot(val_bleus)\n",
    "                plt.title('val_bleus')\n",
    "                plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 19%|██████▉                             | 2654/13828 [25:09<1:49:20,  1.70it/s]"
     ]
    }
   ],
   "source": [
    "train(phase=2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "num_steps = 40\n",
    "val_bleus = []\n",
    "with torch.no_grad():\n",
    "    model.eval()\n",
    "    bleus = []\n",
    "    val_corpus = open('./corpus_val_split.txt', 'r').readlines()\n",
    "    val_data_loader = torch.utils.data.DataLoader(dataset=EuroParlDataset(corpus=val_corpus), batch_size=32, shuffle=True, collate_fn=collate_fn)\n",
    "    for index, data in enumerate(tqdm(val_data_loader), 0):\n",
    "        inputs, valid_lens = data\n",
    "        inputs, valid_lens = inputs.to(device), valid_lens.to(device)\n",
    "        emb_inputs = embedding(inputs)\n",
    "        _, channel_outputs = model(emb_inputs, valid_lens, phase=1)\n",
    "        # The first token decoded is<bos>\n",
    "        outputs = torch.cat([torch.full([inputs.shape[0], 1], source_vocab['<bos>'], dtype=torch.long, device=device), \n",
    "                             torch.full([inputs.shape[0], num_steps - 1], source_vocab['<pad>'], dtype=torch.long, device=device)], \n",
    "                            dim=1).to(device)\n",
    "        # continue_idx marks which sentences can continue to be generated\n",
    "        continue_idx = torch.arange(inputs.shape[0], device=device)\n",
    "        num_step = 0\n",
    "        while not len(continue_idx) == 0 and num_step < num_steps - 1:\n",
    "            emb_outputs = embedding(outputs[continue_idx, :num_step + 1])\n",
    "            pred_words = model.decoder(emb_outputs, channel_outputs[continue_idx], valid_lens[continue_idx], mode='validate').argmax(dim=2)[:, -1:]\n",
    "            outputs[continue_idx, num_step + 1] = pred_words.squeeze(1)\n",
    "            continue_idx = continue_idx[(pred_words != source_vocab['<eos>']).squeeze(1)]\n",
    "            num_step += 1\n",
    "        for i in range(inputs.shape[0]):\n",
    "            bleus.append(sentence_bleu([list(inputs[i].cpu().numpy())], list(outputs[i, 1:].cpu().numpy()), smoothing_function=SmoothingFunction().method1))\n",
    "        if index == 2:\n",
    "            break\n",
    "    print('val sample:')\n",
    "    try:\n",
    "        print('val sample:')\n",
    "        for i in range(5):\n",
    "            print(source_vocab.to_tokens(list(inputs[i].cpu().numpy())), '\\n->\\n', source_vocab.to_tokens(list(outputs[i, 1:].cpu().numpy())))\n",
    "    except:\n",
    "    pass\n",
    "#    for i in range(5):\n",
    "#        print(source_vocab.to_tokens(list(inputs[i].cpu().numpy())), '\\n->\\n', source_vocab.to_tokens(list(outputs[i, 1:].cpu().numpy())))\n",
    "    print(f'val bleu mean:{sum(bleus) / len(bleus)}')\n",
    "    val_bleus.append(sum(bleus) / len(bleus))\n",
    "    plt.plot(val_bleus)\n",
    "    plt.title('val_bleus')\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "train(phase=2)"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "# valid_lens只有eos 没有bos\n",
    "def train(model=model, clipping_max=CONFIG.clipping_max, num_steps=CONFIG.num_steps, phase=1):\n",
    "    \n",
    "#     def init_weights(m):\n",
    "#         if type(m) == nn.Linear:\n",
    "#             nn.init.kaiming_uniform_(m.weight)\n",
    "    criterion = MaskedSoftmaxCELoss()\n",
    "    \n",
    "    \n",
    "    if phase == 1:\n",
    "        mi_optimizer = torch.optim.Adam(mi_model.parameters(), lr=5e-5)\n",
    "        mi_model.apply(init_weights)\n",
    "        for epoch in range(20):\n",
    "            running_mi_loss = 0.\n",
    "            batch_cnt = 0\n",
    "            batch_num = len(data_loader)\n",
    "            for index, data in enumerate(tqdm(data_loader), 0):\n",
    "                # phase == 1\n",
    "                mi_optimizer.zero_grad()\n",
    "                inputs, valid_lens = data\n",
    "                inputs, valid_lens = inputs.to(device), valid_lens.to(device)\n",
    "                emb_inputs = embedding(inputs)\n",
    "                encode_outputs, channel_outputs = model(emb_inputs, valid_lens, phase=1)\n",
    "                x, y = mi_model(encode_outputs, channel_outputs, valid_lens)\n",
    "                mi_loss = -mi_criterion(x, y)\n",
    "                mi_loss.backward()\n",
    "                torch.nn.utils.clip_grad_norm_(mi_model.parameters(), clipping_max)\n",
    "                mi_optimizer.step()\n",
    "                running_mi_loss += float(mi_loss.data)\n",
    "                batch_mi_loss_list.append(float(mi_loss.data))\n",
    "                if batch_cnt > batch_num / 5:\n",
    "                    print(f'now batch:{index} in epoch {epoch}')\n",
    "                    batch_cnt = 0\n",
    "                    plt.plot(batch_mi_loss_list)\n",
    "                    plt.title('batch_mi_loss_list')\n",
    "                    plt.show()\n",
    "                batch_cnt += 1\n",
    "                \n",
    "            \n",
    "            with torch.no_grad():\n",
    "                print('===' * 10, 'epoch:', epoch, 'loss:', running_mi_loss)\n",
    "                epoch_mi_loss_list.append(running_mi_loss)\n",
    "                plt.plot(epoch_mi_loss_list)\n",
    "                plt.title('epoch_mi_loss_list')\n",
    "                plt.show()\n",
    "            \n",
    "    else:\n",
    "        optimizer = torch.optim.Adam(chain(embedding.parameters(), model.parameters()), lr=1e-3)\n",
    "#         model.apply(init_weights)\n",
    "        val_bleus = []\n",
    "        for epoch in range(15):\n",
    "            running_total_loss, running_mi_loss = 0., 0.  # 初始化loss\n",
    "            model.train()\n",
    "            batch_cnt = 0\n",
    "            batch_num = len(data_loader)\n",
    "            \n",
    "            for index, data in enumerate(tqdm(data_loader), 0):\n",
    "                # phase == 2\n",
    "                optimizer.zero_grad()\n",
    "                inputs, valid_lens = data\n",
    "                inputs, valid_lens = inputs.to(device), valid_lens.to(device)\n",
    "                emb_inputs = embedding(inputs)\n",
    "                encode_outputs, channel_outputs, outputs = model(emb_inputs, valid_lens, emb_inputs, embedding, phase=2)\n",
    "\n",
    "#                 x, y = mi_model(encode_outputs, channel_outputs, valid_lens)\n",
    "#                 mi_loss = -mi_criterion(x, y)\n",
    "#                 if batch_cnt % 5000 == 4999:\n",
    "#                     print(f'sample:{source_vocab.to_tokens(inputs[0, :valid_lens[0], :])}->{source_vocab.to_tokens(outputs[0, :valid_lens[0], :].argmax(dim=1))}')\n",
    "                transceiver_loss = criterion(outputs, inputs, valid_lens).mean()\n",
    "#                 total_loss = transceiver_loss + CONFIG.loss_lambda * mi_loss\n",
    "                total_loss = transceiver_loss\n",
    "                total_loss.backward()\n",
    "                torch.nn.utils.clip_grad_norm_(chain(embedding.parameters(), model.parameters()), clipping_max)\n",
    "                optimizer.step()\n",
    "                running_total_loss += float(total_loss.data)\n",
    "#                 running_mi_loss += float(mi_loss.data)\n",
    "                batch_total_loss_list.append(float(total_loss.data))\n",
    "#                 batch_mi_loss_list.append(float(mi_loss.data))            \n",
    "\n",
    "                batch_cnt += 1\n",
    "                if batch_cnt > batch_num / 5:\n",
    "                    print(f'now batch:{index} in epoch {epoch}')\n",
    "                    batch_cnt = 0\n",
    "#                     plt.plot(batch_mi_loss_list)\n",
    "#                     plt.title('batch_mi_loss_list')\n",
    "#                     plt.show()\n",
    "                    plt.plot(batch_total_loss_list)\n",
    "                    plt.title('batch_total_loss_list')\n",
    "                    plt.show()\n",
    "\n",
    "            print('===' * 10, 'epoch:', epoch, 'loss:', running_total_loss)\n",
    "            try:\n",
    "                print('train sample:')\n",
    "                for i in range(5):\n",
    "                    print(source_vocab.to_tokens(list(inputs[i].cpu().numpy())), '\\n->\\n', source_vocab.to_tokens(list(outputs[i, 1:].detach().cpu().argmax(dim=1).numpy())))\n",
    "                \n",
    "            except:\n",
    "                pass\n",
    "            \n",
    "            epoch_total_loss_list.append(running_total_loss)\n",
    "#             epoch_mi_loss_list.append(running_mi_loss)\n",
    "            plt.plot(epoch_total_loss_list)\n",
    "            plt.title('epoch_total_loss_list')\n",
    "            plt.show()\n",
    "#             plt.plot(epoch_mi_loss_list)\n",
    "#             plt.title('epoch_mi_loss_list')\n",
    "#             plt.show()\n",
    "            \n",
    "            if epoch <= 1 or epoch_total_loss_list[-1] < epoch_total_loss_list[-2]:\n",
    "                torch.save(model.state_dict(), 'model.pth')\n",
    "                torch.save(embedding.state_dict(), 'embedding.pth')\n",
    "    \n",
    "            with torch.no_grad():\n",
    "                model.eval()\n",
    "                bleus = []\n",
    "                val_corpus = open('./corpus_val_split.txt', 'r').readlines()\n",
    "                val_data_loader = torch.utils.data.DataLoader(dataset=EuroParlDataset(corpus=val_corpus), batch_size=32, shuffle=True, collate_fn=collate_fn)\n",
    "                for index, data in enumerate(tqdm(val_data_loader), 0):\n",
    "                    inputs, valid_lens = data\n",
    "                    inputs, valid_lens = inputs.to(device), valid_lens.to(device)\n",
    "                    emb_inputs = embedding(inputs)\n",
    "                    _, channel_outputs = model(emb_inputs, valid_lens, phase=1)\n",
    "                    # 解码的第一个词元是<bos>\n",
    "                    outputs = torch.cat([torch.full([inputs.shape[0], 1], source_vocab['<bos>'], dtype=torch.long, device=device), \n",
    "                                         torch.full([inputs.shape[0], num_steps - 1], source_vocab['<pad>'], dtype=torch.long, device=device)], \n",
    "                                        dim=1).to(device)\n",
    "                    # continue_idx标志哪些句子还可以继续生成\n",
    "                    continue_idx = torch.arange(inputs.shape[0], device=device)\n",
    "                    num_step = 0\n",
    "                    while not len(continue_idx) == 0 and num_step < num_steps - 1:\n",
    "                        emb_outputs = embedding(outputs[continue_idx, :num_step + 1])\n",
    "                        pred_words = model.decoder(emb_outputs, channel_outputs[continue_idx], valid_lens[continue_idx], mode='validate').argmax(dim=2)[:, -1:]\n",
    "                        outputs[continue_idx, num_step + 1] = pred_words.squeeze(1)\n",
    "                        continue_idx = continue_idx[(pred_words != source_vocab['<eos>']).squeeze(1)]\n",
    "                        num_step += 1\n",
    "                    for i in range(inputs.shape[0]):\n",
    "                        bleus.append(sentence_bleu([list(inputs[i].cpu().numpy())], list(outputs[i, 1:].cpu().numpy()), smoothing_function=SmoothingFunction().method1))\n",
    "                print('val sample:')\n",
    "                for i in range(5):\n",
    "                    print(source_vocab.to_tokens(list(inputs[i].cpu().numpy())), '\\n->\\n', source_vocab.to_tokens(list(outputs[i, 1:].cpu().numpy())))\n",
    "                print(f'val bleu mean:{sum(bleus) / len(bleus)}')\n",
    "                val_bleus.append(sum(bleus) / len(bleus))\n",
    "                plt.plot(val_bleus)\n",
    "                plt.title('val_bleus')\n",
    "                plt.show()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.10.5 64-bit",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.5"
  },
  "vscode": {
   "interpreter": {
    "hash": "bbc3c3d932324566a9bf4b4a52ddf64063695fc3adbf25b3fda92572428493bb"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
