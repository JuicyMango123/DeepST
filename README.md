# DeepST

## Initializing text2vid

### Create and Setup Conda Environment

* Download Conda
[Miniconda](https://docs.conda.io/en/latest/miniconda.html#linux-installers)
```sh
bash Miniconda3-latest-Linux-x86_64.sh
```

* Create Conda Environment
```sh
conda create --name myenv python=3.7
conda activate myenv
```

* Install Required Libraries
```sh
pip install tqdm
pip install librosa
pip install numba
pip install imageio
pip install pandas
pip install PyYAML
pip install scikit-image
pip install ffmpeg-python
pip install imageio-ffmpeg
sudo apt-get install ffmpeg
pip install google-cloud-texttospeech
pip install google-cloud-speech
pip install six
pip install requests
pip install Flask
pip install torch
pip install opencv-python
pip install opencv-contrib-python
Conda install pyaudio
```

### Wav2Lip Setup
Make sure model files are downloaded and put in appropriate
folder from the `wav2lip` repo, on the machine where the decoding code will run (server).
* GAN model: `wav2lip_gan.pth` should be present in
  `Wav2Lip/checkpoints`. Pretrained model can be downloaded from following
  [link](https://iiitaphyd-my.sharepoint.com/:u:/g/personal/radrabha_m_research_iiit_ac_in/EdjI7bZlgApMqsVoEUUXpLsBxqXbn5z8VTmoxp55YNDcIA?e=n9ljGW).
* Face detection model: `s3fd.pth` should be present in 
  `Wav2Lip/face_detection/detection/sfd/s3fd.pth`. Pretrained model can be downloaded from 
  [link1](https://www.adrianbulat.com/downloads/python-fan/s3fd-619a316812.pth)


### Resemble TTS Setup
To use Resemble API, ensure following steps are executed:
* Create an account on [resemble.ai website](https://app.resemble.ai) and create your own 
  [voice](https://app.resemble.ai/voices) by recording 50-100 samples of audio data.
  Resemble allows training one free voice clone with an account. Create a new project. 
  
* Make `resemble_tts/resemble_config.json` with your data. This json has following structure:
  ```
  {
  "voices": { 
    <voice_name>: {
      "token": <api_token>,
      "voice_id": <voice_id>
      },
    } 
  "project_uuid": <project_uuid>
  }
  ```
  where all the variables are strings. `api_token` is the token used for API access 
  (found [here](https://app.resemble.ai/account/api)) and `voice_id` is 8 character resemble voice ID
  (can be found [here](https://app.resemble.ai/docs#voice) by executing the interactive example and copying
  the `uuid`). For default resemble voices, `voice_id` is same as the name of the default voice
  instead of unique 8 character ID. The `voice_name` can be any identifier string for the voice. 
  **Pass the `voice_name` to `--voice` parameter for the relevant script runs using Resemble as TTS.** 
  `project_uuid` is 8 character ID of the project where the voice will be created using the API 
  (can be found [here](https://app.resemble.ai/docs#project) by executing the interactive example and
  copying the `uuid` of the project to contain voice clips generated via API).
  
* **Callback Server setup** <br>
  * For the Resemble TTS to work via API, we use a callback server to receive the voice output
    generated by Resemble. On server (machine where decoding will happen), 
    launch the callback server by 
    ```
    cd resemble_tts
    export FLASK_APP=tts_callback_file.py
    python -m flask run -p <callback_port>
    ```
    This runs a callback server on `<callback_port>` port (default is `5000`) on the server. 
  * If the server's port `<callback_port>` is publicly accessible, then the callback from resemble can be received
    at `http://localhost:<callback_port>`. If server is inside a network, we need to provide a publicly 
    accessible port to the resemble for sending voice data. One way to do so could be to use
    `https://ngrok.com` for creating an HTTP tunnel. Create a ngrok account and
    follow [instructions](https://dashboard.ngrok.com/get-started/setup) to install
    it on your server. Launch tunnel forwarding to local port `<callback_port>` where the callback server is 
    listening by running: 
    ```
    ./ngrok http <callback_port>
    ```
    This port forwards a publicly accessible link to our
    callback server. The publicly accessible link (`<link>`) is
    available as output where the ngrok command was run in 
    `Forwarding` section as `<link> -> http://localhost:<callback_port>`.
  * **Pass the `<link>` variable or appropriate publicly accessible callback server address to the
    `--resemble_callback_url` parameter for the relevant script runs using Resemble as TTS.**
    
### Initialize Code
* Run inference streaming pipline
```sh
python inference_streaming_pipeline.py -it text \
                                   	-TTS Resemble \
                                   	--checkpoint_path checkpoints/wav2lip_gan.pth \
                                   	--face ../dataset/Demo.jpg \
                                   	-tif socket \
                                   	--text_port 50007 \
                                   	-vot socket \
                                   	--output_port 8080 \
                                   	--voice DeepSVid \
                                   	--resemble_callback_url  https://7855-184-103-165-113.ngrok.io
```
* Run input stream socket on reciever
```sh
python input_stream_socket.py -it text \
                              -tif terminal \
                              --HOST localhost \
                              --PORT 50007
```
* Stream Result Video
```sh
ffplay -f avi http://localhost:8080
```
