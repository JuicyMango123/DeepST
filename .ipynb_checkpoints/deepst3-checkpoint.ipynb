{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "2fd29b74-a890-4cdd-b843-4e902c6e2017",
   "metadata": {},
   "outputs": [
    {
     "ename": "UnicodeDecodeError",
     "evalue": "'charmap' codec can't decode byte 0x90 in position 6877: character maps to <undefined>",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mUnicodeDecodeError\u001b[0m                        Traceback (most recent call last)",
      "Input \u001b[1;32mIn [1]\u001b[0m, in \u001b[0;36m<cell line: 149>\u001b[1;34m()\u001b[0m\n\u001b[0;32m    146\u001b[0m         tokens \u001b[38;5;241m=\u001b[39m [token \u001b[38;5;28;01mfor\u001b[39;00m line \u001b[38;5;129;01min\u001b[39;00m tokens \u001b[38;5;28;01mfor\u001b[39;00m token \u001b[38;5;129;01min\u001b[39;00m line]\n\u001b[0;32m    147\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m collections\u001b[38;5;241m.\u001b[39mCounter(tokens)\n\u001b[1;32m--> 149\u001b[0m vocab_list \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mopen\u001b[39;49m\u001b[43m(\u001b[49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43mcorpus_train_vocab.txt\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m)\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mreadlines\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    150\u001b[0m vocab_dict \u001b[38;5;241m=\u001b[39m {}\n\u001b[0;32m    151\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m key_value_pair \u001b[38;5;129;01min\u001b[39;00m vocab_list:\n",
      "File \u001b[1;32m~\\AppData\\Local\\Programs\\Python\\Python310\\lib\\encodings\\cp1252.py:23\u001b[0m, in \u001b[0;36mIncrementalDecoder.decode\u001b[1;34m(self, input, final)\u001b[0m\n\u001b[0;32m     22\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mdecode\u001b[39m(\u001b[38;5;28mself\u001b[39m, \u001b[38;5;28minput\u001b[39m, final\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mFalse\u001b[39;00m):\n\u001b[1;32m---> 23\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mcodecs\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mcharmap_decode\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43minput\u001b[39;49m\u001b[43m,\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43merrors\u001b[49m\u001b[43m,\u001b[49m\u001b[43mdecoding_table\u001b[49m\u001b[43m)\u001b[49m[\u001b[38;5;241m0\u001b[39m]\n",
      "\u001b[1;31mUnicodeDecodeError\u001b[0m: 'charmap' codec can't decode byte 0x90 in position 6877: character maps to <undefined>"
     ]
    }
   ],
   "source": [
    "#!/usr/bin/env python3\n",
    "# -*- coding: utf-8 -*-\n",
    "\"\"\"\n",
    "Created on Thu Jan 26 19:52:16 2023\n",
    "\n",
    "@author: jerrylee\n",
    "\"\"\"\n",
    "import numpy as np # linear algebra\n",
    "import pandas as pd # data processing, CSV file I/O (e.g. pd.read_csv)\n",
    "\n",
    "# Input data files are available in the read-only \"../input/\" directory\n",
    "# For example, running this (by clicking run or pressing Shift+Enter) will list all files under the input directory\n",
    "\n",
    "import os\n",
    "import re\n",
    "# for dirname, _, filenames in os.walk('/kaggle/input'):\n",
    "#     for filename in filenames:\n",
    "#         print(os.path.join(dirname, filename))\n",
    "\n",
    "import torch\n",
    "import random\n",
    "device = 'cuda' if torch.cuda.is_available() else 'cpu'\n",
    "import torch.nn as nn\n",
    "from glob import glob\n",
    "from matplotlib import pyplot as plt\n",
    "import collections\n",
    "from tqdm import tqdm\n",
    "from itertools import chain\n",
    "from nltk.translate.bleu_score import sentence_bleu, SmoothingFunction\n",
    "\n",
    "class Config:\n",
    "    train_test_ratio = 0.9\n",
    "    E = 128\n",
    "    V = 128\n",
    "    L = None\n",
    "    N = None\n",
    "    # 取decoder第一个维度=V的内容作为三个transformer decoder的一部分输入\n",
    "    # channel: AWGN\n",
    "    sigma = 0.1\n",
    "    loss_lambda = 1\n",
    "    clipping_max = 1.\n",
    "    num_steps = 40\n",
    "CONFIG = Config()\n",
    "\n",
    "# txt_list = glob('/Users/jerrylee/Desktop/code/txt/en/*')\n",
    "# print(txt_list)\n",
    "\n",
    "# file_cnt = 0\n",
    "# text = []  # 整个corpus分句子\n",
    "# # 将标点前补充空格\n",
    "# def no_space(char, prev_char):\n",
    "#     return char in set(',.!?') and prev_char != ' '\n",
    "\n",
    "# for txt_file in tqdm(txt_list):\n",
    "# #     if file_cnt % 1000 == 999:\n",
    "# #         print(f'已处理{file_cnt}个文本')\n",
    "#     unprocessed_text = open(txt_file, 'r').read().replace('\\xa0', ' ')\n",
    "#     splitted_text = re.split(r'\\n|<.*>|\\.|!|\\?', unprocessed_text)\n",
    "#     i = 0\n",
    "#     while i <= len(splitted_text) - 1:\n",
    "#         if splitted_text[i] == '' or splitted_text[i] == ' ':\n",
    "#             del splitted_text[i]\n",
    "#             continue\n",
    "                \n",
    "#         if len(splitted_text[i]) > 30:\n",
    "#             space_cnt = 0\n",
    "#             j = 0\n",
    "#             while j <= len(splitted_text[i]) - 1:\n",
    "#                 if splitted_text[i][j] == ' ':\n",
    "#                     space_cnt += 1\n",
    "#                 j += 1\n",
    "#                 if space_cnt == 30:\n",
    "#                     splitted_text.append(splitted_text[i][:j - 1])\n",
    "#                     splitted_text[i] = splitted_text[i][j:]\n",
    "#                     j = 0\n",
    "#                     space_cnt = 0\n",
    "#         i += 1\n",
    "#     text += splitted_text\n",
    "# # # text切分1/10\n",
    "# text = text[:int(len(text) / 10)]\n",
    "    \n",
    "# # corpus按行写到txt\n",
    "# train_txt = open('/Users/jerrylee/Desktop/code/corpus_train.txt', 'w')\n",
    "# val_txt = open('/Users/jerrylee/Desktop/code/corpus_val.txt', 'w')\n",
    "\n",
    "# train_len = int(len(text) * CONFIG.train_test_ratio)\n",
    "# for sentence in tqdm(text[:train_len]):\n",
    "#     out = [' ' + char if j > 0 and no_space(char, sentence[j - 1]) else char\n",
    "#         for j, char in enumerate(sentence)]\n",
    "#     train_txt.write((''.join(out)).strip() + '\\n')\n",
    "    \n",
    "# for sentence in tqdm(text[train_len:]):\n",
    "#     out = [' ' + char if j > 0 and no_space(char, sentence[j - 1]) else char\n",
    "#         for j, char in enumerate(sentence)]\n",
    "#     val_txt.write((''.join(out)).strip() + '\\n')\n",
    "\n",
    "\n",
    "class Vocab:  \n",
    "#   text vocabulary\n",
    "    # __init__ sorts the tokens by frequency in descending order, and assigns an index to each token\n",
    "    def __init__(self, tokens=None, min_freq=0, reserved_tokens=None): \n",
    "        if tokens is None:\n",
    "            tokens = []\n",
    "        if reserved_tokens is None:\n",
    "            reserved_tokens = []\n",
    "        counter = tokens\n",
    "        self._token_freqs = sorted(counter.items(), key=lambda x: x[1],  \n",
    "                                   reverse=True)            # A list of tokens sorted by frequency\n",
    "        # Unknown tokens have an index of 0\n",
    "        self.idx_to_token = ['<unk>'] + reserved_tokens  # List, idx corresponds to the position of token\n",
    "        self.token_to_idx = {token: idx\n",
    "                             for idx, token in enumerate(self.idx_to_token)}\n",
    "        for token, freq in self._token_freqs:\n",
    "            if freq < min_freq:\n",
    "                break\n",
    "            if token not in self.token_to_idx:\n",
    "                self.idx_to_token.append(token)\n",
    "                self.token_to_idx[token] = len(self.idx_to_token) - 1\n",
    "\n",
    "    def __len__(self): # returns the length of the vocabulary\n",
    "        return len(self.idx_to_token)\n",
    "\n",
    "    def __getitem__(self, tokens): # returns the index of a given token\n",
    "        if not isinstance(tokens, (list, tuple)):\n",
    "            return self.token_to_idx.get(tokens, self.unk)\n",
    "        return [self.__getitem__(token) for token in tokens]\n",
    "\n",
    "    def to_tokens(self, indices): # returns the token corresponding to a given index\n",
    "        if not isinstance(indices, (list, tuple)):\n",
    "            return self.idx_to_token[indices]\n",
    "        return [self.idx_to_token[index] for index in indices]\n",
    "\n",
    "    @property\n",
    "    def unk(self):  # Unknown tokens have an index of 0\n",
    "        return 0\n",
    "\n",
    "    @property\n",
    "    def token_freqs(self): # returns the list of token frequencies that was sorted in descending order during initialization of the Vocab class.\n",
    "        return self._token_freqs\n",
    "\n",
    "def count_corpus(tokens):  \n",
    "    \"\"\"Count the frequency of words\"\"\"\n",
    "    # The tokens here are 1D list or 2D list\n",
    "    if len(tokens) == 0 or isinstance(tokens[0], list):\n",
    "        # Flattens a list of tokens into a list\n",
    "        tokens = [token for line in tokens for token in line]\n",
    "    return collections.Counter(tokens)\n",
    "\n",
    "vocab_list = open('corpus_train_vocab.txt').readlines()\n",
    "vocab_dict = {}\n",
    "for key_value_pair in vocab_list:\n",
    "    key_value_pair = key_value_pair.strip().split()\n",
    "    vocab_dict[key_value_pair[0]] = int(key_value_pair[1])\n",
    "source_vocab = Vocab(collections.Counter(vocab_dict), reserved_tokens=['<pad>', '<eos>', '<bos>'])\n",
    "\n",
    "train_corpus = open('corpus_train_split.txt', 'r').readlines()  # 还有\\n未处理\n",
    "\n",
    "class EuroParlDataset(torch.utils.data.Dataset):\n",
    "    def __init__(self, vocab=source_vocab, corpus=train_corpus):\n",
    "        self.vocab = vocab\n",
    "        self.corpus = corpus\n",
    "        \n",
    "    def __len__(self):\n",
    "        return len(self.corpus)\n",
    "    \n",
    "    def __getitem__(self, index):\n",
    "        sentence = self.corpus[index].strip().split() + ['<eos>']\n",
    "        return self.vocab[sentence], len(sentence)\n",
    "    \n",
    "\n",
    "def collate_fn(batch_data):\n",
    "    batch_data.sort(key=lambda xi: len(xi[0]), reverse=True)\n",
    "    data_length = [xi[1] for xi in batch_data]\n",
    "    data = [torch.tensor(xi[0]) for xi in batch_data]\n",
    "    padded_data = nn.utils.rnn.pad_sequence(data, batch_first=True, padding_value=1)\n",
    "    return padded_data, torch.tensor(data_length)\n",
    "\n",
    "data_loader = torch.utils.data.DataLoader(dataset=EuroParlDataset(), batch_size=32, shuffle=True, collate_fn=collate_fn)\n",
    "\n",
    "torch.set_printoptions(threshold=np.inf)\n",
    "# mi需要mask 先mask取出来再sample\n",
    "# decoder也需要mask\n",
    "# phase=2时候需要chain\n",
    "class PositionalEncoding(nn.Module):\n",
    "    \"\"\"位置编码\"\"\"\n",
    "    def __init__(self, num_hiddens, dropout, max_len=1000):\n",
    "        super(PositionalEncoding, self).__init__()\n",
    "        self.dropout = nn.Dropout(dropout)\n",
    "        # 创建一个足够长的P\n",
    "        self.P = torch.zeros((1, max_len, num_hiddens))\n",
    "        X = torch.arange(max_len, dtype=torch.float32).reshape(\n",
    "            -1, 1) / torch.pow(10000, torch.arange(\n",
    "            0, num_hiddens, 2, dtype=torch.float32) / num_hiddens)\n",
    "        self.P[:, :, 0::2] = torch.sin(X)\n",
    "        self.P[:, :, 1::2] = torch.cos(X)\n",
    "\n",
    "    def forward(self, X):\n",
    "        X = X + self.P[:, :X.shape[1], :].to(X.device)\n",
    "        return self.dropout(X)\n",
    "\n",
    "class MyEmbedding(nn.Module):\n",
    "    def __init__(self, vocab=source_vocab):\n",
    "        super(MyEmbedding, self).__init__()\n",
    "        self.embedding = nn.Embedding(len(vocab), CONFIG.E, padding_idx=vocab['<pad>'])\n",
    "        \n",
    "    def forward(self, X):\n",
    "        return self.embedding(X)\n",
    "    \n",
    "class Encoder(nn.Module):\n",
    "    def __init__(self, vocab=source_vocab):\n",
    "        super(Encoder, self).__init__()\n",
    "        self.position_encoding = PositionalEncoding(CONFIG.V, dropout=0.1)\n",
    "        self.transformer_encoder1 = nn.TransformerEncoderLayer(d_model=CONFIG.V, nhead=8, dim_feedforward=512,  # 别人的参数\n",
    "                                                              batch_first=True)\n",
    "        self.transformer_encoder2 = nn.TransformerEncoderLayer(d_model=CONFIG.V, nhead=8, dim_feedforward=512,  # 别人的参数\n",
    "                                                              batch_first=True)\n",
    "        self.transformer_encoder3 = nn.TransformerEncoderLayer(d_model=CONFIG.V, nhead=8, dim_feedforward=512,  # 别人的参数\n",
    "                                                              batch_first=True)\n",
    "        self.linear1 = nn.Linear(CONFIG.V, 2 * CONFIG.V)\n",
    "        self.relu1 = nn.ReLU()\n",
    "        self.linear2 = nn.Linear(2 * CONFIG.V, 16)\n",
    "        self.relu2 = nn.ReLU()\n",
    "        \n",
    "    def forward(self, X, valid_lens):\n",
    "        mask = (torch.arange((X.shape[1]), device=device).unsqueeze(0) >= valid_lens.unsqueeze(1)).to(device)\n",
    "        X2 = self.position_encoding(X)\n",
    "        X3 = self.transformer_encoder1(X2, src_key_padding_mask=mask)\n",
    "        X4 = self.transformer_encoder2(X3, src_key_padding_mask=mask)\n",
    "        X5 = self.transformer_encoder3(X4, src_key_padding_mask=mask)\n",
    "        X6 = self.linear1(X5)\n",
    "        X7 = self.relu1(X6)\n",
    "        X8 = self.linear2(X7)\n",
    "        X9 = self.relu2(X8)\n",
    "        return X9\n",
    "    \n",
    "def Channel(X):  # AWGN\n",
    "    return X + torch.normal(0, CONFIG.sigma, size=X.shape).to(device)\n",
    "        \n",
    "class Decoder(nn.Module):\n",
    "    def __init__(self, vocab=source_vocab):\n",
    "        super(Decoder, self).__init__()\n",
    "        # reshape\n",
    "        self.position_encoding = PositionalEncoding(CONFIG.V, dropout=0.1)\n",
    "        self.linear1 = nn.Linear(16, 2 * CONFIG.V)\n",
    "        self.relu1 = nn.ReLU()\n",
    "        self.linear2 = nn.Linear(2 * CONFIG.V, CONFIG.V)\n",
    "        self.relu2 = nn.ReLU()\n",
    "        self.transformer_decoder1 = nn.TransformerDecoderLayer(d_model=CONFIG.V, nhead=8, dim_feedforward=512,  # 别人的参数\n",
    "                                                              batch_first=True)\n",
    "        self.transformer_decoder2 = nn.TransformerDecoderLayer(d_model=CONFIG.V, nhead=8, dim_feedforward=512,  # 别人的参数\n",
    "                                                              batch_first=True)\n",
    "        self.transformer_decoder3 = nn.TransformerDecoderLayer(d_model=CONFIG.V, nhead=8, dim_feedforward=512,  # 别人的参数\n",
    "                                                              batch_first=True)\n",
    "        self.linear3 = nn.Linear(CONFIG.V, len(source_vocab))\n",
    "#         self.softmax = nn.Softmax(dim=2)  # ?\n",
    "\n",
    "    def forward(self, emb_decoder_input, channel_output, origin_len, tgt_mask=None, mode='train'):\n",
    "        memory_mask = (torch.arange((channel_output.shape[1]), dtype=torch.float32,\n",
    "                            device=device)[None, :] >= origin_len[:, None]).to(device)\n",
    "        channel_output = self.linear1(channel_output)\n",
    "        channel_output = self.relu1(channel_output)\n",
    "        channel_output = self.linear2(channel_output)\n",
    "        memory = self.relu2(channel_output)\n",
    "        emb_decoder_input = self.position_encoding(emb_decoder_input)\n",
    "        X6 = self.transformer_decoder1(emb_decoder_input, memory, tgt_mask=tgt_mask, memory_key_padding_mask=memory_mask, tgt_key_padding_mask=memory_mask if mode == 'train' else None)\n",
    "        X7 = self.transformer_decoder2(X6, memory, tgt_mask=tgt_mask, memory_key_padding_mask=memory_mask, tgt_key_padding_mask=memory_mask if mode == 'train' else None)\n",
    "        X8 = self.transformer_decoder3(X7, memory, tgt_mask=tgt_mask, memory_key_padding_mask=memory_mask, tgt_key_padding_mask=memory_mask if mode == 'train' else None)\n",
    "        X9 = self.linear3(X8)\n",
    "        return X9\n",
    "#         return self.softmax(X9)\n",
    "\n",
    "class DeepSC(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(DeepSC, self).__init__()\n",
    "        self.encoder = Encoder()\n",
    "        self.channel = Channel\n",
    "        self.decoder = Decoder()\n",
    "        \n",
    "    def forward(self, emb_encoder_input, valid_lens, emb_decoder_input=None, embedding=None, phase=1):  # valid_lens是含<eos>\n",
    "        '''\n",
    "        x: (batch_size, N, E)\n",
    "        '''\n",
    "        encode_result = self.encoder(emb_encoder_input, valid_lens)\n",
    "        channel_outputs = self.channel(encode_result)\n",
    "        if phase == 2:\n",
    "            mask = (torch.triu(torch.ones(emb_decoder_input.shape[1], emb_decoder_input.shape[1])) == 1).transpose(0, 1)\n",
    "            mask = (mask.masked_fill(mask == 0, True).masked_fill(mask == 1, False)).to(device)\n",
    "            return encode_result, self.channel(encode_result), \\\n",
    "                   self.decoder(torch.cat([embedding(torch.full([emb_decoder_input.shape[0], 1], source_vocab['<bos>'], dtype=torch.long, device=device)), \n",
    "                                        emb_decoder_input[:, :-1, :]], dim=1).to(device), \n",
    "                                channel_outputs,\n",
    "                                valid_lens, \n",
    "                                mask)\n",
    "        else:\n",
    "            return encode_result, self.channel(encode_result)\n",
    "        \n",
    "class MI(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(MI, self).__init__()\n",
    "        self.linear1 = nn.Linear(16 * 2, 2 * CONFIG.V)\n",
    "        self.relu1 = nn.ReLU()\n",
    "        self.linear2 = nn.Linear(2 * CONFIG.V, 2 * CONFIG.V)\n",
    "        self.relu2 = nn.ReLU()\n",
    "        self.linear3 = nn.Linear(2 * CONFIG.V, 1)\n",
    "        self.relu3 = nn.ReLU()\n",
    "        \n",
    "    def network(self, X, Y):\n",
    "        return self.relu3(self.linear3(self.relu2(self.linear2(self.relu1(self.linear1(torch.cat([X, Y], dim=1)))))))\n",
    "        \n",
    "    def forward(self, X, Y, valid_lens): \n",
    "        \n",
    "        mask = (torch.arange((X.shape[1]), dtype=torch.long,\n",
    "                            device=X.device)[None, :] >= valid_lens[:, None]).reshape(-1)\n",
    "        # 把X和Y先reshape，再拿出来\n",
    "        X = X.reshape(-1, 16)\n",
    "        Y = Y.reshape(-1, 16)\n",
    "        \n",
    "        X = X[mask == False]\n",
    "        Y = Y[mask == False]\n",
    "        # sample\n",
    "        sample_size = X.shape[0]\n",
    "        idx = list(range(sample_size))\n",
    "        random.shuffle(idx)\n",
    "        idx = torch.tensor(idx).to(device)\n",
    "        X = X[idx]\n",
    "        Y = Y[idx]\n",
    "        idx_shuffle = list(range(sample_size))\n",
    "        random.shuffle(idx_shuffle)\n",
    "        idx_shuffle = torch.tensor(idx_shuffle).to(device)\n",
    "        shuffle_Y = Y[idx_shuffle]\n",
    "        \n",
    "        output_joint = self.network(X, Y)\n",
    "        output_marginal = self.network(X, shuffle_Y)\n",
    "        \n",
    "        return output_joint, output_marginal\n",
    "    \n",
    "def mi_criterion(x, y):\n",
    "    max_y = torch.max(y)\n",
    "    return torch.mean(x) - (max_y + torch.log(torch.mean(torch.exp(y - max_y))))\n",
    "\n",
    "class MaskedSoftmaxCELoss(nn.CrossEntropyLoss):\n",
    "    def sequence_mask(self, X, valid_len, value=0):\n",
    "        \"\"\"\n",
    "        在序列中屏蔽不相关的项\n",
    "        X: (batch_size, maxlen)\n",
    "        \"\"\"\n",
    "        maxlen = X.size(1)\n",
    "        mask = torch.arange((maxlen), dtype=torch.float32,\n",
    "                            device=X.device)[None, :] < valid_len[:, None]\n",
    "        X[~mask] = value\n",
    "        return X\n",
    "    \n",
    "    \"\"\"带遮蔽的softmax交叉熵损失函数\"\"\"\n",
    "    # pred的形状：(batch_size,num_steps,vocab_size)\n",
    "    # label的形状：(batch_size,num_steps)\n",
    "    # valid_len的形状：(batch_size,)\n",
    "    def forward(self, pred, label, valid_len):\n",
    "        weights = torch.ones_like(label)\n",
    "        weights = self.sequence_mask(weights, valid_len)\n",
    "        self.reduction='mean'\n",
    "        unweighted_loss = super(MaskedSoftmaxCELoss, self).forward(\n",
    "            pred.permute(32, 2, 1), label)\n",
    "        weighted_loss = (unweighted_loss * weights).mean(dim=1)\n",
    "        return weighted_loss\n",
    "\n",
    "embedding = MyEmbedding()\n",
    "embedding.to(device)\n",
    "model = DeepSC()\n",
    "model.to(device)\n",
    "mi_model = MI()\n",
    "mi_model.to(device)\n",
    "\n",
    "batch_total_loss_list, batch_mi_loss_list = [], []\n",
    "epoch_total_loss_list, epoch_mi_loss_list = [], []\n",
    "\n",
    "# valid_lens只有eos 没有bos\n",
    "def train(model=model, clipping_max=CONFIG.clipping_max, num_steps=CONFIG.num_steps, phase=1):\n",
    "    \n",
    "#     def init_weights(m):\n",
    "#         if type(m) == nn.Linear:\n",
    "#             nn.init.kaiming_uniform_(m.weight)\n",
    "    criterion = MaskedSoftmaxCELoss()\n",
    "    \n",
    "    \n",
    "    if phase == 1:\n",
    "        mi_optimizer = torch.optim.Adam(mi_model.parameters(), lr=5e-5)\n",
    "        mi_model.apply(init_weights)\n",
    "        for epoch in range(20):\n",
    "            running_mi_loss = 0.\n",
    "            batch_cnt = 0\n",
    "            batch_num = len(data_loader)\n",
    "            for index, data in enumerate(tqdm(data_loader), 0):\n",
    "                # phase == 1\n",
    "                mi_optimizer.zero_grad()\n",
    "                inputs, valid_lens = data\n",
    "                inputs, valid_lens = inputs.to(device), valid_lens.to(device)\n",
    "                emb_inputs = embedding(inputs)\n",
    "                encode_outputs, channel_outputs = model(emb_inputs, valid_lens, phase=1)\n",
    "                x, y = mi_model(encode_outputs, channel_outputs, valid_lens)\n",
    "                mi_loss = -mi_criterion(x, y)\n",
    "                mi_loss.backward()\n",
    "                torch.nn.utils.clip_grad_norm_(mi_model.parameters(), clipping_max)\n",
    "                mi_optimizer.step()\n",
    "                running_mi_loss += float(mi_loss.data)\n",
    "                batch_mi_loss_list.append(float(mi_loss.data))\n",
    "                if batch_cnt > batch_num / 5:\n",
    "                    print(f'now batch:{index} in epoch {epoch}')\n",
    "                    batch_cnt = 0\n",
    "                    plt.plot(batch_mi_loss_list)\n",
    "                    plt.title('batch_mi_loss_list')\n",
    "                    plt.show()\n",
    "                batch_cnt += 1\n",
    "                \n",
    "            \n",
    "            with torch.no_grad():\n",
    "                print('===' * 10, 'epoch:', epoch, 'loss:', running_mi_loss)\n",
    "                epoch_mi_loss_list.append(running_mi_loss)\n",
    "                plt.plot(epoch_mi_loss_list)\n",
    "                plt.title('epoch_mi_loss_list')\n",
    "                plt.show()\n",
    "            \n",
    "    else:\n",
    "        optimizer = torch.optim.Adam(chain(embedding.parameters(), model.parameters()), lr=1e-3)\n",
    "#         model.apply(init_weights)\n",
    "        val_bleus = []\n",
    "        for epoch in range(15):\n",
    "            running_total_loss, running_mi_loss = 0., 0.  # 初始化loss\n",
    "            model.train()\n",
    "            batch_cnt = 0\n",
    "            batch_num = len(data_loader)\n",
    "            for index, data in enumerate(tqdm(data_loader), 0):\n",
    "                # phase == 2\n",
    "                optimizer.zero_grad()\n",
    "                inputs, valid_lens = data\n",
    "                inputs, valid_lens = inputs.to(device), valid_lens.to(device)\n",
    "                emb_inputs = embedding(inputs)\n",
    "                encode_outputs, channel_outputs, outputs = model(emb_inputs, valid_lens, emb_inputs, embedding, phase=2)\n",
    "\n",
    "#                 x, y = mi_model(encode_outputs, channel_outputs, valid_lens)\n",
    "#                 mi_loss = -mi_criterion(x, y)\n",
    "#                 if batch_cnt % 5000 == 4999:\n",
    "#                     print(f'sample:{source_vocab.to_tokens(inputs[0, :valid_lens[0], :])}->{source_vocab.to_tokens(outputs[0, :valid_lens[0], :].argmax(dim=1))}')\n",
    "                transceiver_loss = criterion(outputs, inputs, valid_lens).mean()\n",
    "#                 total_loss = transceiver_loss + CONFIG.loss_lambda * mi_loss\n",
    "                total_loss = transceiver_loss\n",
    "                total_loss.backward()\n",
    "                torch.nn.utils.clip_grad_norm_(chain(embedding.parameters(), model.parameters()), clipping_max)\n",
    "                optimizer.step()\n",
    "                running_total_loss += float(total_loss.data)\n",
    "#                 running_mi_loss += float(mi_loss.data)\n",
    "                batch_total_loss_list.append(float(total_loss.data))\n",
    "#                 batch_mi_loss_list.append(float(mi_loss.data))            \n",
    "\n",
    "                batch_cnt += 1\n",
    "                if batch_cnt > batch_num / 5:\n",
    "                    print(f'now batch:{index} in epoch {epoch}')\n",
    "                    batch_cnt = 0\n",
    "#                     plt.plot(batch_mi_loss_list)\n",
    "#                     plt.title('batch_mi_loss_list')\n",
    "#                     plt.show()\n",
    "                    plt.plot(batch_total_loss_list)\n",
    "                    plt.title('batch_total_loss_list')\n",
    "                    plt.show()\n",
    "                print('===' * 10, 'epoch:', epoch, 'loss:', running_total_loss)\n",
    "            try:\n",
    "                print('train sample:')\n",
    "                for i in range(5):\n",
    "                    print(source_vocab.to_tokens(list(inputs[i].cpu().numpy())), '\\n->\\n', source_vocab.to_tokens(list(outputs[i, 1:].detach().cpu().argmax(dim=1).numpy())))\n",
    "                \n",
    "            except:\n",
    "                pass\n",
    "            \n",
    "            epoch_total_loss_list.append(running_total_loss)\n",
    "#             epoch_mi_loss_list.append(running_mi_loss)\n",
    "            plt.plot(epoch_total_loss_list)\n",
    "            plt.title('epoch_total_loss_list')\n",
    "            plt.show()\n",
    "#             plt.plot(epoch_mi_loss_list)\n",
    "#             plt.title('epoch_mi_loss_list')\n",
    "#             plt.show()\n",
    "            \n",
    "            if epoch <= 1 or epoch_total_loss_list[-1] < epoch_total_loss_list[-2]:\n",
    "                torch.save(model.state_dict(), 'model.pth')\n",
    "                torch.save(embedding.state_dict(), 'embedding.pth')\n",
    "            with torch.no_grad():\n",
    "                model.eval()\n",
    "                bleus = []\n",
    "                val_corpus = open('corpus_val_split.txt', 'r').readlines()\n",
    "                val_data_loader = torch.utils.data.DataLoader(dataset=EuroParlDataset(corpus=val_corpus), batch_size=32, shuffle=True, collate_fn=collate_fn)\n",
    "                for index, data in enumerate(tqdm(val_data_loader), 0):\n",
    "                    inputs, valid_lens = data\n",
    "                    inputs, valid_lens = inputs.to(device), valid_lens.to(device)\n",
    "                    emb_inputs = embedding(inputs)\n",
    "                    _, channel_outputs = model(emb_inputs, valid_lens, phase=1)\n",
    "                    # 解码的第一个词元是<bos>\n",
    "                    outputs = torch.cat([torch.full([inputs.shape[0], 1], source_vocab['<bos>'], dtype=torch.long, device=device), \n",
    "                                         torch.full([inputs.shape[0], num_steps - 1], source_vocab['<pad>'], dtype=torch.long, device=device)], \n",
    "                                        dim=1).to(device)\n",
    "                    # continue_idx标志哪些句子还可以继续生成\n",
    "                    continue_idx = torch.arange(inputs.shape[0], device=device)\n",
    "                    num_step = 0\n",
    "                    while not len(continue_idx) == 0 and num_step < num_steps - 1:\n",
    "                        emb_outputs = embedding(outputs[continue_idx, :num_step + 1])\n",
    "                        pred_words = model.decoder(emb_outputs, channel_outputs[continue_idx], valid_lens[continue_idx], mode='validate').argmax(dim=2)[:, -1:]\n",
    "                        outputs[continue_idx, num_step + 1] = pred_words.squeeze(1)\n",
    "                        continue_idx = continue_idx[(pred_words != source_vocab['<eos>']).squeeze(1)]\n",
    "                        num_step += 1\n",
    "                    for i in range(inputs.shape[0]):\n",
    "                        bleus.append(sentence_bleu([list(inputs[i].cpu().numpy())], list(outputs[i, 1:].cpu().numpy()), smoothing_function=SmoothingFunction().method1))\n",
    "                print('val sample:')\n",
    "                for i in range(5):\n",
    "                    print(source_vocab.to_tokens(list(inputs[i].cpu().numpy())), '\\n->\\n', source_vocab.to_tokens(list(outputs[i, 1:].cpu().numpy())))\n",
    "                print(f'val bleu mean:{sum(bleus) / len(bleus)}')\n",
    "                val_bleus.append(sum(bleus) / len(bleus))\n",
    "                plt.plot(val_bleus)\n",
    "                plt.title('val_bleus')\n",
    "                plt.show()\n",
    "                \n",
    "train(phase=2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "582a5cf9-9df7-4496-94a7-574435772c33",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
